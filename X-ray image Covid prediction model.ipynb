{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Name- Covid virus predictions using X-ray images dataset.\n",
    "## Author- Shubham Kumar\n",
    "## Dated- May07,2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imutils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a0a3b13fbb4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mimutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVGG16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAveragePooling2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'imutils'"
     ]
    }
   ],
   "source": [
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import Dropout \n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first cell consists of importing of various libraries in Python.\n",
    "--> First of all we imported matplotlib.pyplot which is a collection of functions that make matplotlib work like       MATLAB. Each pyplot function makes some change to a figure: e.g., creates a figure, creates a plotting area in     a figure, plots some lines in a plotting area, decorates the plot with labels, etc.\n",
    "--> Now imported various tensorflow layers for fast numerical computing. It is a foundation library that can be         used to create Deep Learning models directly or by using wrapper libraries.\n",
    "--> At last I imported sklearn library as it contains a lot of efficient tools for machine learning and statistical     modeling including classification, regression, clustering and dimensionality reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset= r'/home/aarush100616/Downloads/Data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In above cell I have given location for dataset on which predictions are to be made.It differs from system to system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INIT_LR=1e-3\n",
    "EPOCHS=10\n",
    "BS=8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above cell is used to crete model in this first of all INIT_LR is the initial learning rate at which model will learn,EPOCHS is the reading the quantity of images,BS is the number of times you want to throw the images for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args={}\n",
    "args['dataset']=dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "iPaths=list(paths.list_images(args[\"dataset\"]))\n",
    "\n",
    "data=[]\n",
    "labels=[]\n",
    "\n",
    "for iPath in iPaths:\n",
    "    label=iPath.split(os.path.sep)[-2]\n",
    "    image=cv2.imread(iPath)\n",
    "    image=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "    image=cv2.resize(image,(224,224))\n",
    "    data.append(image)\n",
    "    labels.append(label)\n",
    "    \n",
    "data=np.array(data)/255.0\n",
    "labels=np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import skimage\n",
    "from skimage import filters\n",
    "Cimages = os.listdir(dataset+\"/Covid\")\n",
    "Nimages = os.listdir(dataset+\"/Normal\")\n",
    "import numpy as np\n",
    "def plotter(i):\n",
    "    normal = cv2.imread(dataset+\"/Normal//\"+Nimages[i])\n",
    "    normal = skimage.transform.resize(normal, (150, 150, 3))\n",
    "    coronavirus = cv2.imread(dataset+\"/Covid//\"+Cimages[i])\n",
    "    coronavirus = skimage.transform.resize(coronavirus, (150, 150, 3) , mode = 'reflect')\n",
    "    pair = np.concatenate((normal, coronavirus), axis=1)\n",
    "    print(\"Normal Chest X-ray Vs Covid-19 Chest X-ray\")\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.imshow(pair)\n",
    "    plt.show()\n",
    "for i in range(0,5):\n",
    "    plotter(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LB=LabelBinarizer()\n",
    "labels=LB.fit_transform(labels)\n",
    "labels=to_categorical(labels)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as sklearn_train_test_split\n",
    "(X_train,X_test,Y_train,Y_test)=train_test_split(data,labels,test_size=0.20,random_state=42,stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainAug=ImageDataGenerator(rotation_range=15,fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainAug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmodel=VGG16(weights='imagenet',include_top=False,input_tensor=Input(shape=(224,224,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmodel=bmodel.output\n",
    "hmodel=AveragePooling2D(pool_size=(4,4))(hmodel)\n",
    "hmodel=Flatten(name='flatten')(hmodel)\n",
    "hmodel=Dense(64,activation='relu')(hmodel)\n",
    "hmodel=Dropout(0.5)(hmodel)\n",
    "hmodel=Dense(2,activation='softmax')(hmodel)\n",
    "\n",
    "model=Model(bmodel.input,hmodel)\n",
    "for layer in bmodel.layers:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_grid = 4\n",
    "L_grid = 4\n",
    "fig, axes= plt.subplots(L_grid,W_grid,figsize=(25,25))\n",
    "axes=axes.ravel()\n",
    "n_training=len(X_train)\n",
    "for i in np.arange(0, L_grid * W_grid):\n",
    "    index=np.random.randint(0,n_training)\n",
    "    axes[i].imshow(X_train[index])\n",
    "    axes[i].set_title(Y_train[index])\n",
    "    axes[i].axis('off')\n",
    "    \n",
    "plt.subplots_adjust(hspace=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "opt= Adam(lr=INIT_LR,decay=INIT_LR/EPOCHS)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n",
    "print(\"Compiling Starts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = model.fit_generator(\n",
    "    trainAug.flow(X_train, Y_train, batch_size=BS),\n",
    "    steps_per_epoch=len(X_train) // BS,\n",
    "    validation_data=(X_test, Y_test),\n",
    "    validation_steps=len(X_test) // BS,\n",
    "    epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 6\n",
    "W = 5\n",
    "fig, axes = plt.subplots(L, W, figsize = (12, 12))\n",
    "axes = axes.ravel()\n",
    "y_pred = model.predict(X_test, batch_size=BS)\n",
    "for i in np.arange(0,L*W):\n",
    "    axes[i].imshow(X_test[i])\n",
    "    axes[i].set_title('Prediction = {}\\n True = {}'.format(y_pred.argmax(axis=1)[i], Y_test.argmax(axis=1)[i]))\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.subplots_adjust(wspace = 1, hspace=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred = model.predict(X_test, batch_size=BS)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "print(classification_report(Y_test.argmax(axis=1), y_pred,target_names=LB.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph for loss\n",
    "plt.plot(R.history['loss'], label='train loss')\n",
    "plt.plot(R.history['val_loss'], label='val loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('LossVal_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph for accuracy\n",
    "plt.plot(R.history['accuracy'], label='train acc')\n",
    "plt.plot(R.history['val_accuracy'], label='val acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(r'/home/aarush100616/Downloads/Data/Model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing import image\n",
    "model=tf.keras.models.load_model(r'/home/aarush100616/Downloads/Data/Model.h5')\n",
    "from keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img = image.load_img('/home/aarush100616/Downloads/Data/Normal/IM-0135-0001.jpeg', target_size=(224, 224)) #insert a random covid-19 x-ray image\n",
    "imgplot = plt.imshow(img)\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "img_data = preprocess_input(x)\n",
    "classes = model.predict(img_data)\n",
    "New_pred = np.argmax(classes, axis=1)\n",
    "if New_pred==[1]:\n",
    "  print('Prediction: Normal')\n",
    "else:\n",
    "  print('Prediction: Corona')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img('/home/aarush100616/Downloads/Data/Covid/1-s2.0-S1684118220300682-main.pdf-002-a2.png', target_size=(224, 224)) #insert a random covid-19 x-ray image\n",
    "imgplot = plt.imshow(img)\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "img_data = preprocess_input(x)\n",
    "classes = model.predict(img_data)\n",
    "New_pred = np.argmax(classes, axis=1)\n",
    "if New_pred==[1]:\n",
    "  print('Prediction: Normal')\n",
    "else:\n",
    "  print('Prediction: Corona')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
